Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

# All requested packages already installed.

Looking in links: https://download.pytorch.org/whl/torch_stable.html
Requirement already satisfied: torch==1.5.0+cu101 in /home/at2507/miniconda3/lib/python3.8/site-packages (1.5.0+cu101)
Requirement already satisfied: torchvision==0.6.0+cu101 in /home/at2507/miniconda3/lib/python3.8/site-packages (0.6.0+cu101)
Requirement already satisfied: future in /home/at2507/miniconda3/lib/python3.8/site-packages (from torch==1.5.0+cu101) (0.18.2)
Requirement already satisfied: numpy in /home/at2507/miniconda3/lib/python3.8/site-packages (from torch==1.5.0+cu101) (1.18.1)
Requirement already satisfied: pillow>=4.1.1 in /home/at2507/miniconda3/lib/python3.8/site-packages (from torchvision==0.6.0+cu101) (7.2.0)
[{'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml', 'name': 'id=supsup~seed=0~sparsity=1', 'sparsity': 1, 'seed': 0, 'log-dir': 'runs/supsupseed_at/num_mask_3', 'epochs': 10, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml', 'name': 'id=supsup~seed=0~sparsity=2', 'sparsity': 2, 'seed': 0, 'log-dir': 'runs/supsupseed_at/num_mask_3', 'epochs': 10, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml', 'name': 'id=supsup~seed=0~sparsity=4', 'sparsity': 4, 'seed': 0, 'log-dir': 'runs/supsupseed_at/num_mask_3', 'epochs': 10, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml', 'name': 'id=supsup~seed=0~sparsity=8', 'sparsity': 8, 'seed': 0, 'log-dir': 'runs/supsupseed_at/num_mask_3', 'epochs': 10, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml', 'name': 'id=supsup~seed=0~sparsity=16', 'sparsity': 16, 'seed': 0, 'log-dir': 'runs/supsupseed_at/num_mask_3', 'epochs': 10, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml', 'name': 'id=supsup~seed=0~sparsity=32', 'sparsity': 32, 'seed': 0, 'log-dir': 'runs/supsupseed_at/num_mask_3', 'epochs': 10, 'data': './data'}]
=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml
=> Saving data in runs/supsupseed_at/num_mask_3/id=supsup~seed=0~sparsity=1~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
Set sparsity of conv1 to 0.04259259259259259
Set sparsity of layer1.0.conv1 to 0.011111111111111112
Set sparsity of layer1.0.conv2 to 0.011111111111111112
Set sparsity of layer1.1.conv1 to 0.011111111111111112
Set sparsity of layer1.1.conv2 to 0.011111111111111112
Set sparsity of layer2.0.conv1 to 0.008333333333333333
Set sparsity of layer2.0.conv2 to 0.005555555555555556
Set sparsity of layer2.0.shortcut.0 to 0.075
Set sparsity of layer2.1.conv1 to 0.005555555555555556
Set sparsity of layer2.1.conv2 to 0.005555555555555556
Set sparsity of layer3.0.conv1 to 0.004166666666666667
Set sparsity of layer3.0.conv2 to 0.002777777777777778
Set sparsity of layer3.0.shortcut.0 to 0.0375
Set sparsity of layer3.1.conv1 to 0.002777777777777778
Set sparsity of layer3.1.conv2 to 0.002777777777777778
Set sparsity of layer4.0.conv1 to 0.0020833333333333333
Set sparsity of layer4.0.conv2 to 0.001388888888888889
Set sparsity of layer4.0.shortcut.0 to 0.01875
Set sparsity of layer4.1.conv1 to 0.001388888888888889
Set sparsity of layer4.1.conv2 to 0.001388888888888889
Set sparsity of linear to 0.20625
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.670147
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.427125

Test set: Average loss: 1.3809, Accuracy: (0.4220)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.440543
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.469890

Test set: Average loss: 1.2459, Accuracy: (0.5040)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.274287
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.673376

Test set: Average loss: 1.2988, Accuracy: (0.4780)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.276788
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.412563

Test set: Average loss: 1.1663, Accuracy: (0.5540)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.197660
Train Epoch: 5 [1280/2500 (50%)]	Loss: 1.186371

Test set: Average loss: 1.1415, Accuracy: (0.5560)

Train Epoch: 6 [0/2500 (0%)]	Loss: 1.112493
Train Epoch: 6 [1280/2500 (50%)]	Loss: 1.138815

Test set: Average loss: 1.1120, Accuracy: (0.6020)

Train Epoch: 7 [0/2500 (0%)]	Loss: 1.054748
Train Epoch: 7 [1280/2500 (50%)]	Loss: 1.255114

Test set: Average loss: 1.0826, Accuracy: (0.6040)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.994740
Train Epoch: 8 [1280/2500 (50%)]	Loss: 1.152931

Test set: Average loss: 1.0452, Accuracy: (0.6200)

Train Epoch: 9 [0/2500 (0%)]	Loss: 1.002316
Train Epoch: 9 [1280/2500 (50%)]	Loss: 1.225324

Test set: Average loss: 1.0112, Accuracy: (0.6220)

Train Epoch: 10 [0/2500 (0%)]	Loss: 1.071194
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.959360

Test set: Average loss: 1.0116, Accuracy: (0.6260)

Task RandSplitCIFAR100: 1
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.588011
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.240922

Test set: Average loss: 1.3839, Accuracy: (0.3740)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.346356
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.191770

Test set: Average loss: 1.2122, Accuracy: (0.4860)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.241507
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.107436

Test set: Average loss: 1.2676, Accuracy: (0.4580)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.115978
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.099398

Test set: Average loss: 1.1226, Accuracy: (0.5060)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.078092
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.990577

Test set: Average loss: 1.1681, Accuracy: (0.5280)

Train Epoch: 6 [0/2500 (0%)]	Loss: 1.116952
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.978119

Test set: Average loss: 1.0741, Accuracy: (0.5480)

Train Epoch: 7 [0/2500 (0%)]	Loss: 1.002890
Train Epoch: 7 [1280/2500 (50%)]	Loss: 1.005116

Test set: Average loss: 1.0725, Accuracy: (0.5460)

Train Epoch: 8 [0/2500 (0%)]	Loss: 1.095356
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.935571

Test set: Average loss: 1.0686, Accuracy: (0.5680)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.999814
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.899153

Test set: Average loss: 1.0153, Accuracy: (0.5760)

Train Epoch: 10 [0/2500 (0%)]	Loss: 1.054352
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.907903

Test set: Average loss: 1.0014, Accuracy: (0.5960)

Task RandSplitCIFAR100: 2
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.705031
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.477625

Test set: Average loss: 1.2177, Accuracy: (0.4480)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.274584
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.134025

Test set: Average loss: 1.0903, Accuracy: (0.5500)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.110198
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.092616

Test set: Average loss: 1.0102, Accuracy: (0.5760)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.108021
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.970225

Test set: Average loss: 0.9514, Accuracy: (0.5960)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.947330
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.918054

Test set: Average loss: 0.8763, Accuracy: (0.6360)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.900682
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.932030

Test set: Average loss: 0.8458, Accuracy: (0.6500)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.849342
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.896088

Test set: Average loss: 0.8146, Accuracy: (0.6660)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.777943
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.838183

Test set: Average loss: 0.7904, Accuracy: (0.6860)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.656553
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.745237

Test set: Average loss: 0.7632, Accuracy: (0.6840)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.764591
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.799269

Test set: Average loss: 0.7493, Accuracy: (0.6840)

Testing 0: RandSplitCIFAR100 (0)

Test set: Accuracy: (0.6200%)

Testing 1: RandSplitCIFAR100 (1)

Test set: Accuracy: (0.6020%)

Testing 2: RandSplitCIFAR100 (2)

Test set: Accuracy: (0.6940%)

=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml
=> Saving data in runs/supsupseed_at/num_mask_3/id=supsup~seed=0~sparsity=2~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
Set sparsity of conv1 to 0.08518518518518518
Set sparsity of layer1.0.conv1 to 0.022222222222222223
Set sparsity of layer1.0.conv2 to 0.022222222222222223
Set sparsity of layer1.1.conv1 to 0.022222222222222223
Set sparsity of layer1.1.conv2 to 0.022222222222222223
Set sparsity of layer2.0.conv1 to 0.016666666666666666
Set sparsity of layer2.0.conv2 to 0.011111111111111112
Set sparsity of layer2.0.shortcut.0 to 0.15
Set sparsity of layer2.1.conv1 to 0.011111111111111112
Set sparsity of layer2.1.conv2 to 0.011111111111111112
Set sparsity of layer3.0.conv1 to 0.008333333333333333
Set sparsity of layer3.0.conv2 to 0.005555555555555556
Set sparsity of layer3.0.shortcut.0 to 0.075
Set sparsity of layer3.1.conv1 to 0.005555555555555556
Set sparsity of layer3.1.conv2 to 0.005555555555555556
Set sparsity of layer4.0.conv1 to 0.004166666666666667
Set sparsity of layer4.0.conv2 to 0.002777777777777778
Set sparsity of layer4.0.shortcut.0 to 0.0375
Set sparsity of layer4.1.conv1 to 0.002777777777777778
Set sparsity of layer4.1.conv2 to 0.002777777777777778
Set sparsity of linear to 0.4125
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.653363
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.427278

Test set: Average loss: 1.4702, Accuracy: (0.3880)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.500456
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.439388

Test set: Average loss: 1.2498, Accuracy: (0.5360)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.335362
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.307976

Test set: Average loss: 1.1842, Accuracy: (0.5440)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.222614
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.228262

Test set: Average loss: 1.0519, Accuracy: (0.6140)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.125589
Train Epoch: 5 [1280/2500 (50%)]	Loss: 1.065761

Test set: Average loss: 1.0273, Accuracy: (0.6260)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.907672
Train Epoch: 6 [1280/2500 (50%)]	Loss: 1.027872

Test set: Average loss: 0.9998, Accuracy: (0.6300)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.916671
Train Epoch: 7 [1280/2500 (50%)]	Loss: 1.177889

Test set: Average loss: 0.9704, Accuracy: (0.6260)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.908238
Train Epoch: 8 [1280/2500 (50%)]	Loss: 1.038638

Test set: Average loss: 0.9618, Accuracy: (0.6320)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.936224
Train Epoch: 9 [1280/2500 (50%)]	Loss: 1.071726

Test set: Average loss: 0.9236, Accuracy: (0.6580)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.975449
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.811662

Test set: Average loss: 0.9372, Accuracy: (0.6380)

Task RandSplitCIFAR100: 1
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.744792
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.202106

Test set: Average loss: 1.2078, Accuracy: (0.4960)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.244084
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.028335

Test set: Average loss: 1.1464, Accuracy: (0.5160)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.115920
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.050372

Test set: Average loss: 1.0959, Accuracy: (0.5260)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.037284
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.054870

Test set: Average loss: 1.0030, Accuracy: (0.5780)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.067012
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.931292

Test set: Average loss: 0.9948, Accuracy: (0.5980)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.921998
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.886081

Test set: Average loss: 1.0252, Accuracy: (0.6020)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.952109
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.833776

Test set: Average loss: 0.9439, Accuracy: (0.6220)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.991020
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.917983

Test set: Average loss: 0.9898, Accuracy: (0.6100)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.897011
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.820481

Test set: Average loss: 0.9130, Accuracy: (0.6260)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.921524
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.903733

Test set: Average loss: 0.8986, Accuracy: (0.6220)

Task RandSplitCIFAR100: 2
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.637194
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.266896

Test set: Average loss: 1.0890, Accuracy: (0.5540)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.238724
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.021840

Test set: Average loss: 0.9342, Accuracy: (0.6120)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.980934
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.924400

Test set: Average loss: 0.8947, Accuracy: (0.6580)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.056459
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.862574

Test set: Average loss: 0.8315, Accuracy: (0.6760)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.870574
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.738485

Test set: Average loss: 0.7913, Accuracy: (0.6740)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.740014
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.838346

Test set: Average loss: 0.7340, Accuracy: (0.7020)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.739310
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.730832

Test set: Average loss: 0.7423, Accuracy: (0.7040)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.666318
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.705423

Test set: Average loss: 0.6649, Accuracy: (0.7360)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.587391
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.648703

Test set: Average loss: 0.6459, Accuracy: (0.7680)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.611593
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.699440

Test set: Average loss: 0.5999, Accuracy: (0.7700)

Testing 0: RandSplitCIFAR100 (0)

Test set: Accuracy: (0.6520%)

Testing 1: RandSplitCIFAR100 (1)

Test set: Accuracy: (0.6300%)

Testing 2: RandSplitCIFAR100 (2)

Test set: Accuracy: (0.7820%)

=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml
=> Saving data in runs/supsupseed_at/num_mask_3/id=supsup~seed=0~sparsity=4~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
Set sparsity of conv1 to 0.17037037037037037
Set sparsity of layer1.0.conv1 to 0.044444444444444446
Set sparsity of layer1.0.conv2 to 0.044444444444444446
Set sparsity of layer1.1.conv1 to 0.044444444444444446
Set sparsity of layer1.1.conv2 to 0.044444444444444446
Set sparsity of layer2.0.conv1 to 0.03333333333333333
Set sparsity of layer2.0.conv2 to 0.022222222222222223
Set sparsity of layer2.0.shortcut.0 to 0.3
Set sparsity of layer2.1.conv1 to 0.022222222222222223
Set sparsity of layer2.1.conv2 to 0.022222222222222223
Set sparsity of layer3.0.conv1 to 0.016666666666666666
Set sparsity of layer3.0.conv2 to 0.011111111111111112
Set sparsity of layer3.0.shortcut.0 to 0.15
Set sparsity of layer3.1.conv1 to 0.011111111111111112
Set sparsity of layer3.1.conv2 to 0.011111111111111112
Set sparsity of layer4.0.conv1 to 0.008333333333333333
Set sparsity of layer4.0.conv2 to 0.005555555555555556
Set sparsity of layer4.0.shortcut.0 to 0.075
Set sparsity of layer4.1.conv1 to 0.005555555555555556
Set sparsity of layer4.1.conv2 to 0.005555555555555556
Set sparsity of linear to 0.5
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.692012
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.431587

Test set: Average loss: 1.2608, Accuracy: (0.5040)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.499085
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.354725

Test set: Average loss: 1.1410, Accuracy: (0.5840)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.161736
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.054455

Test set: Average loss: 1.0967, Accuracy: (0.5960)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.051624
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.134844

Test set: Average loss: 1.0728, Accuracy: (0.6060)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.064403
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.957768

Test set: Average loss: 0.9617, Accuracy: (0.6560)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.892583
Train Epoch: 6 [1280/2500 (50%)]	Loss: 1.020511

Test set: Average loss: 0.9802, Accuracy: (0.6380)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.870041
Train Epoch: 7 [1280/2500 (50%)]	Loss: 1.027225

Test set: Average loss: 0.8810, Accuracy: (0.6800)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.810076
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.883308

Test set: Average loss: 0.9210, Accuracy: (0.6360)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.801495
Train Epoch: 9 [1280/2500 (50%)]	Loss: 1.056587

Test set: Average loss: 0.8710, Accuracy: (0.6600)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.883058
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.695422

Test set: Average loss: 0.8331, Accuracy: (0.6740)

Task RandSplitCIFAR100: 1
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.810473
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.208986

Test set: Average loss: 1.3166, Accuracy: (0.4680)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.337086
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.041916

Test set: Average loss: 1.1417, Accuracy: (0.5460)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.126935
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.013962

Test set: Average loss: 1.0656, Accuracy: (0.5720)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.012200
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.079024

Test set: Average loss: 0.9825, Accuracy: (0.6080)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.009599
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.889908

Test set: Average loss: 1.0210, Accuracy: (0.5680)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.889871
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.847211

Test set: Average loss: 0.9535, Accuracy: (0.6060)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.894934
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.806683

Test set: Average loss: 0.9102, Accuracy: (0.6420)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.902007
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.783731

Test set: Average loss: 0.9113, Accuracy: (0.6560)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.790900
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.681137

Test set: Average loss: 0.8764, Accuracy: (0.6520)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.884296
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.740912

Test set: Average loss: 0.8254, Accuracy: (0.6560)

Task RandSplitCIFAR100: 2
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.704539
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.339169

Test set: Average loss: 1.0047, Accuracy: (0.6040)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.053789
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.912734

Test set: Average loss: 0.8338, Accuracy: (0.6800)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.904650
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.768793

Test set: Average loss: 0.8348, Accuracy: (0.6920)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.895698
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.753466

Test set: Average loss: 0.7075, Accuracy: (0.7420)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.715819
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.599462

Test set: Average loss: 0.6090, Accuracy: (0.7660)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.566193
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.825289

Test set: Average loss: 0.6442, Accuracy: (0.7660)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.622036
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.661263

Test set: Average loss: 0.6669, Accuracy: (0.7500)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.611651
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.628276

Test set: Average loss: 0.5625, Accuracy: (0.7900)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.445634
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.540891

Test set: Average loss: 0.5452, Accuracy: (0.7820)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.453575
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.546560

Test set: Average loss: 0.5292, Accuracy: (0.7980)

Testing 0: RandSplitCIFAR100 (0)

Test set: Accuracy: (0.6780%)

Testing 1: RandSplitCIFAR100 (1)

Test set: Accuracy: (0.6680%)

Testing 2: RandSplitCIFAR100 (2)

Test set: Accuracy: (0.7940%)

=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml
=> Saving data in runs/supsupseed_at/num_mask_3/id=supsup~seed=0~sparsity=8~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
Set sparsity of conv1 to 0.34074074074074073
Set sparsity of layer1.0.conv1 to 0.08888888888888889
Set sparsity of layer1.0.conv2 to 0.08888888888888889
Set sparsity of layer1.1.conv1 to 0.08888888888888889
Set sparsity of layer1.1.conv2 to 0.08888888888888889
Set sparsity of layer2.0.conv1 to 0.06666666666666667
Set sparsity of layer2.0.conv2 to 0.044444444444444446
Set sparsity of layer2.0.shortcut.0 to 0.5
Set sparsity of layer2.1.conv1 to 0.044444444444444446
Set sparsity of layer2.1.conv2 to 0.044444444444444446
Set sparsity of layer3.0.conv1 to 0.03333333333333333
Set sparsity of layer3.0.conv2 to 0.022222222222222223
Set sparsity of layer3.0.shortcut.0 to 0.3
Set sparsity of layer3.1.conv1 to 0.022222222222222223
Set sparsity of layer3.1.conv2 to 0.022222222222222223
Set sparsity of layer4.0.conv1 to 0.016666666666666666
Set sparsity of layer4.0.conv2 to 0.011111111111111112
Set sparsity of layer4.0.shortcut.0 to 0.15
Set sparsity of layer4.1.conv1 to 0.011111111111111112
Set sparsity of layer4.1.conv2 to 0.011111111111111112
Set sparsity of linear to 0.5
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.725032
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.378657

Test set: Average loss: 1.3081, Accuracy: (0.4860)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.431661
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.274261

Test set: Average loss: 1.0455, Accuracy: (0.6140)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.015991
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.107903

Test set: Average loss: 1.0197, Accuracy: (0.6000)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.940695
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.978845

Test set: Average loss: 0.9395, Accuracy: (0.6520)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.877051
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.988934

Test set: Average loss: 0.8522, Accuracy: (0.6700)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.800909
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.792368

Test set: Average loss: 0.9078, Accuracy: (0.6400)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.701149
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.919493

Test set: Average loss: 0.8555, Accuracy: (0.6740)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.695326
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.896100

Test set: Average loss: 0.8206, Accuracy: (0.6980)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.694426
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.869219

Test set: Average loss: 0.8144, Accuracy: (0.6840)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.760845
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.589963

Test set: Average loss: 0.7858, Accuracy: (0.7060)

Task RandSplitCIFAR100: 1
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.719915
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.301954

Test set: Average loss: 1.1236, Accuracy: (0.5040)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.118012
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.946150

Test set: Average loss: 0.9783, Accuracy: (0.5900)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.956884
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.852695

Test set: Average loss: 0.9524, Accuracy: (0.6320)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.897000
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.936105

Test set: Average loss: 0.8801, Accuracy: (0.6680)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.842449
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.743880

Test set: Average loss: 0.9143, Accuracy: (0.6420)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.734707
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.781166

Test set: Average loss: 0.8143, Accuracy: (0.6760)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.810963
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.693047

Test set: Average loss: 0.8363, Accuracy: (0.6900)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.778328
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.713303

Test set: Average loss: 0.8510, Accuracy: (0.6880)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.734670
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.731970

Test set: Average loss: 0.7924, Accuracy: (0.6980)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.689654
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.602386

Test set: Average loss: 0.7601, Accuracy: (0.7180)

Task RandSplitCIFAR100: 2
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.704389
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.196878

Test set: Average loss: 1.0062, Accuracy: (0.6280)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.029921
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.827314

Test set: Average loss: 0.7306, Accuracy: (0.7180)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.727930
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.661250

Test set: Average loss: 0.6410, Accuracy: (0.7620)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.713904
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.603920

Test set: Average loss: 0.6246, Accuracy: (0.7780)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.655960
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.677249

Test set: Average loss: 0.6036, Accuracy: (0.7980)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.524893
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.658177

Test set: Average loss: 0.5578, Accuracy: (0.7960)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.566758
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.553938

Test set: Average loss: 0.5274, Accuracy: (0.8220)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.491359
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.450151

Test set: Average loss: 0.4968, Accuracy: (0.8260)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.331033
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.503979

Test set: Average loss: 0.4567, Accuracy: (0.8340)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.389776
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.428245

Test set: Average loss: 0.4762, Accuracy: (0.8140)

Testing 0: RandSplitCIFAR100 (0)

Test set: Accuracy: (0.7040%)

Testing 1: RandSplitCIFAR100 (1)

Test set: Accuracy: (0.7200%)

Testing 2: RandSplitCIFAR100 (2)

Test set: Accuracy: (0.8160%)

=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml
=> Saving data in runs/supsupseed_at/num_mask_3/id=supsup~seed=0~sparsity=16~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
Set sparsity of conv1 to 0.5
Set sparsity of layer1.0.conv1 to 0.17777777777777778
Set sparsity of layer1.0.conv2 to 0.17777777777777778
Set sparsity of layer1.1.conv1 to 0.17777777777777778
Set sparsity of layer1.1.conv2 to 0.17777777777777778
Set sparsity of layer2.0.conv1 to 0.13333333333333333
Set sparsity of layer2.0.conv2 to 0.08888888888888889
Set sparsity of layer2.0.shortcut.0 to 0.5
Set sparsity of layer2.1.conv1 to 0.08888888888888889
Set sparsity of layer2.1.conv2 to 0.08888888888888889
Set sparsity of layer3.0.conv1 to 0.06666666666666667
Set sparsity of layer3.0.conv2 to 0.044444444444444446
Set sparsity of layer3.0.shortcut.0 to 0.5
Set sparsity of layer3.1.conv1 to 0.044444444444444446
Set sparsity of layer3.1.conv2 to 0.044444444444444446
Set sparsity of layer4.0.conv1 to 0.03333333333333333
Set sparsity of layer4.0.conv2 to 0.022222222222222223
Set sparsity of layer4.0.shortcut.0 to 0.3
Set sparsity of layer4.1.conv1 to 0.022222222222222223
Set sparsity of layer4.1.conv2 to 0.022222222222222223
Set sparsity of linear to 0.5
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.663375
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.338183

Test set: Average loss: 1.1464, Accuracy: (0.5580)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.260542
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.310032

Test set: Average loss: 1.0048, Accuracy: (0.6260)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.019594
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.060323

Test set: Average loss: 1.0117, Accuracy: (0.6300)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.946077
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.988729

Test set: Average loss: 0.9384, Accuracy: (0.6660)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.873038
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.928055

Test set: Average loss: 0.8517, Accuracy: (0.6900)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.734492
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.909528

Test set: Average loss: 0.8717, Accuracy: (0.6800)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.712332
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.900176

Test set: Average loss: 0.8116, Accuracy: (0.7060)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.687994
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.806484

Test set: Average loss: 0.7665, Accuracy: (0.7100)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.639345
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.876520

Test set: Average loss: 0.7843, Accuracy: (0.6960)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.795499
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.564250

Test set: Average loss: 0.7791, Accuracy: (0.7100)

Task RandSplitCIFAR100: 1
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.846081
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.159273

Test set: Average loss: 1.1087, Accuracy: (0.5320)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.128820
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.858082

Test set: Average loss: 1.0471, Accuracy: (0.5480)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.013995
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.939511

Test set: Average loss: 1.0295, Accuracy: (0.5760)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.900690
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.977700

Test set: Average loss: 0.9416, Accuracy: (0.5960)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.905669
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.863611

Test set: Average loss: 0.8906, Accuracy: (0.6700)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.767361
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.750444

Test set: Average loss: 0.8628, Accuracy: (0.6720)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.782103
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.788862

Test set: Average loss: 0.8433, Accuracy: (0.6780)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.787059
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.692977

Test set: Average loss: 0.8883, Accuracy: (0.6720)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.740681
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.727009

Test set: Average loss: 0.8429, Accuracy: (0.6760)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.720740
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.590761

Test set: Average loss: 0.7859, Accuracy: (0.7120)

Task RandSplitCIFAR100: 2
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.666131
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.135378

Test set: Average loss: 0.8704, Accuracy: (0.6640)

Train Epoch: 2 [0/2500 (0%)]	Loss: 0.941525
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.908238

Test set: Average loss: 0.7176, Accuracy: (0.7240)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.732835
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.693462

Test set: Average loss: 0.6929, Accuracy: (0.7480)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.775994
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.677939

Test set: Average loss: 0.6933, Accuracy: (0.7320)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.612480
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.751686

Test set: Average loss: 0.6046, Accuracy: (0.7700)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.484166
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.563983

Test set: Average loss: 0.5331, Accuracy: (0.8040)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.532958
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.572647

Test set: Average loss: 0.5274, Accuracy: (0.8020)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.493956
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.516401

Test set: Average loss: 0.5046, Accuracy: (0.8060)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.339931
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.463259

Test set: Average loss: 0.4854, Accuracy: (0.8100)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.415662
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.437826

Test set: Average loss: 0.4863, Accuracy: (0.8220)

Testing 0: RandSplitCIFAR100 (0)

Test set: Accuracy: (0.7160%)

Testing 1: RandSplitCIFAR100 (1)

Test set: Accuracy: (0.7120%)

Testing 2: RandSplitCIFAR100 (2)

Test set: Accuracy: (0.8280%)

=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml
=> Saving data in runs/supsupseed_at/num_mask_3/id=supsup~seed=0~sparsity=32~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
Set sparsity of conv1 to 0.5
Set sparsity of layer1.0.conv1 to 0.35555555555555557
Set sparsity of layer1.0.conv2 to 0.35555555555555557
Set sparsity of layer1.1.conv1 to 0.35555555555555557
Set sparsity of layer1.1.conv2 to 0.35555555555555557
Set sparsity of layer2.0.conv1 to 0.26666666666666666
Set sparsity of layer2.0.conv2 to 0.17777777777777778
Set sparsity of layer2.0.shortcut.0 to 0.5
Set sparsity of layer2.1.conv1 to 0.17777777777777778
Set sparsity of layer2.1.conv2 to 0.17777777777777778
Set sparsity of layer3.0.conv1 to 0.13333333333333333
Set sparsity of layer3.0.conv2 to 0.08888888888888889
Set sparsity of layer3.0.shortcut.0 to 0.5
Set sparsity of layer3.1.conv1 to 0.08888888888888889
Set sparsity of layer3.1.conv2 to 0.08888888888888889
Set sparsity of layer4.0.conv1 to 0.06666666666666667
Set sparsity of layer4.0.conv2 to 0.044444444444444446
Set sparsity of layer4.0.shortcut.0 to 0.5
Set sparsity of layer4.1.conv1 to 0.044444444444444446
Set sparsity of layer4.1.conv2 to 0.044444444444444446
Set sparsity of linear to 0.5
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.744066
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.272695

Test set: Average loss: 1.0848, Accuracy: (0.5920)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.240325
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.295995

Test set: Average loss: 0.9591, Accuracy: (0.6400)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.941565
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.009506

Test set: Average loss: 0.9439, Accuracy: (0.6540)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.931923
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.976218

Test set: Average loss: 0.9702, Accuracy: (0.6460)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.900685
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.846521

Test set: Average loss: 0.9250, Accuracy: (0.6540)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.819399
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.926583

Test set: Average loss: 0.9547, Accuracy: (0.6500)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.714082
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.819710

Test set: Average loss: 0.8211, Accuracy: (0.7120)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.696126
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.763158

Test set: Average loss: 0.7925, Accuracy: (0.7000)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.639986
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.806785

Test set: Average loss: 0.8148, Accuracy: (0.7200)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.775844
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.550311

Test set: Average loss: 0.7650, Accuracy: (0.7240)

Task RandSplitCIFAR100: 1
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.830331
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.109690

Test set: Average loss: 1.1447, Accuracy: (0.5200)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.027489
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.853234

Test set: Average loss: 1.0480, Accuracy: (0.5760)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.000719
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.898016

Test set: Average loss: 0.8883, Accuracy: (0.6200)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.857948
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.927274

Test set: Average loss: 0.9361, Accuracy: (0.6400)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.949338
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.730605

Test set: Average loss: 0.8570, Accuracy: (0.6540)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.806751
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.714011

Test set: Average loss: 0.8298, Accuracy: (0.6980)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.684227
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.667633

Test set: Average loss: 0.8340, Accuracy: (0.6900)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.732966
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.601166

Test set: Average loss: 0.8262, Accuracy: (0.7000)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.684934
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.687043

Test set: Average loss: 0.7561, Accuracy: (0.7140)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.653150
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.566774

Test set: Average loss: 0.7065, Accuracy: (0.7260)

Task RandSplitCIFAR100: 2
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.756322
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.168807

Test set: Average loss: 0.9550, Accuracy: (0.6400)

Train Epoch: 2 [0/2500 (0%)]	Loss: 0.912234
Train Epoch: 2 [1280/2500 (50%)]	Loss: 0.789673

Test set: Average loss: 0.7509, Accuracy: (0.7180)

Train Epoch: 3 [0/2500 (0%)]	Loss: 0.744237
Train Epoch: 3 [1280/2500 (50%)]	Loss: 0.758500

Test set: Average loss: 0.6858, Accuracy: (0.7260)

Train Epoch: 4 [0/2500 (0%)]	Loss: 0.683609
Train Epoch: 4 [1280/2500 (50%)]	Loss: 0.619004

Test set: Average loss: 0.6600, Accuracy: (0.7400)

Train Epoch: 5 [0/2500 (0%)]	Loss: 0.598154
Train Epoch: 5 [1280/2500 (50%)]	Loss: 0.626401

Test set: Average loss: 0.6130, Accuracy: (0.7720)

Train Epoch: 6 [0/2500 (0%)]	Loss: 0.564454
Train Epoch: 6 [1280/2500 (50%)]	Loss: 0.607042

Test set: Average loss: 0.5331, Accuracy: (0.8020)

Train Epoch: 7 [0/2500 (0%)]	Loss: 0.546077
Train Epoch: 7 [1280/2500 (50%)]	Loss: 0.539889

Test set: Average loss: 0.5305, Accuracy: (0.8120)

Train Epoch: 8 [0/2500 (0%)]	Loss: 0.411415
Train Epoch: 8 [1280/2500 (50%)]	Loss: 0.431041

Test set: Average loss: 0.4699, Accuracy: (0.8320)

Train Epoch: 9 [0/2500 (0%)]	Loss: 0.281447
Train Epoch: 9 [1280/2500 (50%)]	Loss: 0.429317

Test set: Average loss: 0.4830, Accuracy: (0.8240)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.412497
Train Epoch: 10 [1280/2500 (50%)]	Loss: 0.398763

Test set: Average loss: 0.4594, Accuracy: (0.8500)

Testing 0: RandSplitCIFAR100 (0)

Test set: Accuracy: (0.7340%)

Testing 1: RandSplitCIFAR100 (1)

Test set: Accuracy: (0.7260%)

Testing 2: RandSplitCIFAR100 (2)

Test set: Accuracy: (0.8280%)

==> Starting experiment python main.py --config=experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml --name=id=supsup~seed=0~sparsity=1 --sparsity=1 --seed=0 --log-dir=runs/supsupseed_at/num_mask_3 --epochs=10 --data=./data --multigpu=0 
==> Starting experiment python main.py --config=experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml --name=id=supsup~seed=0~sparsity=2 --sparsity=2 --seed=0 --log-dir=runs/supsupseed_at/num_mask_3 --epochs=10 --data=./data --multigpu=0 
==> Starting experiment python main.py --config=experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml --name=id=supsup~seed=0~sparsity=4 --sparsity=4 --seed=0 --log-dir=runs/supsupseed_at/num_mask_3 --epochs=10 --data=./data --multigpu=0 
==> Starting experiment python main.py --config=experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml --name=id=supsup~seed=0~sparsity=8 --sparsity=8 --seed=0 --log-dir=runs/supsupseed_at/num_mask_3 --epochs=10 --data=./data --multigpu=0 
==> Starting experiment python main.py --config=experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml --name=id=supsup~seed=0~sparsity=16 --sparsity=16 --seed=0 --log-dir=runs/supsupseed_at/num_mask_3 --epochs=10 --data=./data --multigpu=0 
==> Starting experiment python main.py --config=experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_3.yaml --name=id=supsup~seed=0~sparsity=32 --sparsity=32 --seed=0 --log-dir=runs/supsupseed_at/num_mask_3 --epochs=10 --data=./data --multigpu=0 
